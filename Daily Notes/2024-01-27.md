
Let $f(x;\theta)$ be a parametric, [[differentiable]], [[C2-continuous]] function acting on the space $x \in \mathbb{R}^k$. Let there be an *oracle labeler* that provides the point-label pairs $\mathcal{D} = \{(x,y)_i\}_{i=1}^N$, however we only have access to a tainted dataset $\mathcal{D}^{\sim} = \{(x,\tilde{y})_i\}_{i=1}^N$ where $\tilde{y}$ may or may not be the same as $y$.

If we find a $\theta$ s.t. $f(x;\theta)\to \tilde{y}; \forall x$ then we have found a model that has sufficiently learned the given labels. However, how can we modify $\theta$ in order to make $f(x;\theta)\to y; \forall x$? As long as $f$ has a V.C. dimension sufficient enough to learn $\mathcal{D}$ , then we only need to identify which labels were incorrectly given, correct the labels, and retrain.

## What properties would [[mislabeled instances]] have?

We can break up their properties in a variety of ways:

### If the [[mislabeled instances lack coherence]]
Then we can assume mislabeled instances are randomly scattered in the space. When this is true, the local neighborhood of instances around mislabeled instances are most likely, if not all, correctly labeled.

If we know the function $f$ has a [[Lipschitz continuous]], then we can bound the [[gradient]] of $f$, but necessarily any bound on the curvature, as the [[eigenvalues]] of the [[Hessian]] will be not be constrained generally.
### If the [[mislabeled instances have coherence]]
Then we can assume there is some pattern in which mislabeled instances are clustered, whether it be along certain directions in the feature space, be highly clustered (high local density of mislabeled instances in a neighborhood).

 When looking at [[Hessian]] of  function, 